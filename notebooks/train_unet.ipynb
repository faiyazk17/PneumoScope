{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94890e5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'typing_extensions'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "%pip install typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf1a91b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'typing_extensions'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "%pip install tensorflow\n",
    "%pip install keras\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a111c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdfde81",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"../data/images\"\n",
    "mask_dir = \"../data/masks\"\n",
    "\n",
    "image_size = (256, 256)\n",
    "all_images = []\n",
    "all_masks = []\n",
    "\n",
    "for filename in os.listdir(image_dir):\n",
    "    image = cv2.imread(os.path.join(image_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, image_size)\n",
    "    all_images.append(image)\n",
    "\n",
    "    mask = cv2.imread(os.path.join(mask_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, image_size)\n",
    "    all_masks.append(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a40397",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(all_images).reshape(-1, 256, 256, 1) / 255.0\n",
    "y = np.array(all_masks).reshape(-1, 256, 256, 1) / 255.0\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c52d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (9637, 256, 256, 1)\n",
      "y_train: (9637, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "042a8e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.13.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\Users\\Faiyaz\\Desktop\\SideProjects\\PneumoScope\\venv\\Lib\\site-packages\n",
      "Requires: tensorflow-intel\n",
      "Required-by: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~eras (c:\\Users\\Faiyaz\\Desktop\\SideProjects\\PneumoScope\\venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c514110",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.compat'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers, models\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# 1. Defining reusable conv block\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconv_block\u001b[39m(inputs, num_filters):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Faiyaz\\Desktop\\SideProjects\\PneumoScope\\venv\\Lib\\site-packages\\tensorflow\\keras\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m applications\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Faiyaz\\Desktop\\SideProjects\\PneumoScope\\venv\\Lib\\site-packages\\keras\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m applications\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Faiyaz\\Desktop\\SideProjects\\PneumoScope\\venv\\Lib\\site-packages\\keras\\__internal__\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m losses\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Faiyaz\\Desktop\\SideProjects\\PneumoScope\\venv\\Lib\\site-packages\\keras\\__internal__\\backend\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _initialize_variables \u001b[38;5;28;01mas\u001b[39;00m initialize_variables\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m track_variable\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Faiyaz\\Desktop\\SideProjects\\PneumoScope\\venv\\Lib\\site-packages\\keras\\src\\__init__.py:21\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m \u001b[33;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[33;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minput_layer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msequential\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Faiyaz\\Desktop\\SideProjects\\PneumoScope\\venv\\Lib\\site-packages\\keras\\src\\models\\__init__.py:18\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msequential\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Faiyaz\\Desktop\\SideProjects\\PneumoScope\\venv\\Lib\\site-packages\\keras\\src\\engine\\functional.py:23\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mitertools\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layout_map \u001b[38;5;28;01mas\u001b[39;00m layout_map_lib\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow.compat'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "# 1. Defining reusable conv block\n",
    "def conv_block(inputs, num_filters):\n",
    "    x = layers.Conv2D(num_filters, (3, 3), padding='same',\n",
    "                      activation='relu')(inputs)\n",
    "    x = layers.Conv2D(num_filters, (3, 3),\n",
    "                      padding='same', activation='relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be148956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Encoder path (downsampling)\n",
    "# This part of the model extracts features from the input image\n",
    "# by applying a series of convolutional layers followed by max pooling\n",
    "inputs = layers.Input((256, 256, 1)) # shape of greyscale chest xrays\n",
    "\n",
    "c1 = conv_block(inputs, 64) # 64 filters in first conv block\n",
    "p1 = layers.MaxPooling2D((2,2))(c1) # downsample by 2x (halves the image size by pooling)\n",
    "\n",
    "c2 = conv_block(p1, 128) # 128 filters in second conv block\n",
    "p2 = layers.MaxPooling2D((2,2))(c2) # downsample by 2x\n",
    "\n",
    "c3 = conv_block(p2, 256) # 256 filters in third conv block\n",
    "p3 = layers.MaxPooling2D((2,2))(c3) # downsample by 2x\n",
    "\n",
    "c4 = conv_block(p3, 512) # 512 filters in fourth conv block\n",
    "p4 = layers.MaxPooling2D((2,2))(c4) # downsample by 2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49412e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Bottleneck layer\n",
    "# This is the deepest layer of the model, where the most abstract features are learned\n",
    "bottleneck = conv_block(p4, 1024) # 1024 filters in bottleneck conv block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c915b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Decoder path (upsampling)\n",
    "# The decoder path mirrors the encoder path, using transposed convolutions to upsample the feature maps\n",
    "# and concatenate them with the corresponding feature maps from the encoder path\n",
    "u1 = layers.UpSampling2D((2,2))(bottleneck) # upsample by 2x\n",
    "u1 = layers.Concatenate()([u1, c4]) # concatenate with encoder feature map\n",
    "c5 = conv_block(u1, 512) # 512 filters in fifth conv block\n",
    "\n",
    "u2 = layers.UpSampling2D((2,2))(c5) # upsample by 2x\n",
    "u2 = layers.Concatenate()([u2, c3]) # concatenate with encoder feature map\n",
    "c6 = conv_block(u2, 256) # 256 filters in sixth conv block\n",
    "\n",
    "u3 = layers.UpSampling2D((2,2))(c6) # upsample by 2x\n",
    "u3 = layers.Concatenate()([u3, c2]) # concatenate with encoder feature map\n",
    "c7 = conv_block(u3, 128) # 128 filters in seventh conv block\n",
    "\n",
    "u4 = layers.UpSampling2D((2,2))(c7) # upsample by 2x\n",
    "u4 = layers.Concatenate()([u4, c1]) # concatenate with encoder feature map\n",
    "c8 = conv_block(u4, 64) # 64 filters in eighth conv block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf869e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Output layer\n",
    "# The final layer of the model produces the segmentation mask\n",
    "output = layers.Conv2D(1, (1,1), activation='sigmoid')(c8) # final output layer with 1 filter (binary segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2faa142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Creating the model\n",
    "# The model is created by specifying the input and output layers\n",
    "model = models.Model(inputs=inputs, outputs=output) # create the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # compile the model with Adam optimizer and binary crossentropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e41e1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def load_data(image_folder, mask_folder, target_size=(256, 256)):\n",
    "    images = []\n",
    "    masks = []\n",
    "    for img_name in os.listdir(image_folder):\n",
    "        img_path = os.path.join(image_folder, img_name)\n",
    "        mask_path = os.path.join(mask_folder, img_name)  # Ensure masks are named similarly\n",
    "        \n",
    "        if os.path.exists(mask_path):  # Check if corresponding mask exists\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Read the image in grayscale\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # Read the mask in grayscale\n",
    "            \n",
    "            if img is not None and mask is not None:  # Ensure image is valid\n",
    "                img_resized = cv2.resize(img, target_size)  # Resize the image\n",
    "                mask_resized = cv2.resize(mask, target_size)  # Resize the mask\n",
    "                \n",
    "                images.append(img_resized)\n",
    "                masks.append(mask_resized)\n",
    "    \n",
    "    print(f\"Loaded {len(images)} images and {len(masks)} masks\")  # Add this to see how many files are loaded\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Use the function with resized images\n",
    "image_folder = '../data/images'  # path to your images\n",
    "mask_folder = '../data/masks'  # path to your masks\n",
    "X, y = load_data(image_folder, mask_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67696276",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Splitting...\")\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Verify the size of X and y\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Shape of y: {y.shape}\")\n",
    "\n",
    "# Make sure you have enough data before splitting\n",
    "if len(X) > 1:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "else:\n",
    "    print(\"Not enough data to split into train/test sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e241b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from keras.src.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "class LivePlotCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        self.val_losses.append(logs[\"val_loss\"])\n",
    "        self.acc.append(logs[\"accuracy\"])\n",
    "        self.val_acc.append(logs[\"val_accuracy\"])\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        # Loss plot\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.losses, label=\"Train Loss\")\n",
    "        plt.plot(self.val_losses, label=\"Val Loss\")\n",
    "        plt.title(\"Loss\")\n",
    "        plt.legend()\n",
    "\n",
    "        # Accuracy plot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.acc, label=\"Train Acc\")\n",
    "        plt.plot(self.val_acc, label=\"Val Acc\")\n",
    "        plt.title(\"Accuracy\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1faf112",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    \"../model_checkpoints/unet_best.h5\",  # Save to this path\n",
    "    monitor=\"val_loss\",                # Check validation loss\n",
    "    save_best_only=True,              # Only save if it's the best\n",
    "    save_weights_only=False,          # Save the full model\n",
    "    verbose=1                          # Print info when saving\n",
    ")\n",
    "\n",
    "live_plot = LivePlotCallback()\n",
    "\n",
    "from keras.src.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "from keras.src.callbacks import ReduceLROnPlateau\n",
    "lr_reduce = ReduceLROnPlateau(factor=0.1, patience=3)\n",
    "\n",
    "%pip install tensorboard\n",
    "from keras.src.callbacks import TensorBoard\n",
    "\n",
    "# Setup TensorBoard callback\n",
    "%load_ext tensorboard\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=1)\n",
    "\n",
    "print(\"✅ Starting model training...\")\n",
    "\n",
    "# 7. Training the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=8,\n",
    "    epochs=50,\n",
    "    callbacks=[checkpoint, live_plot, early_stop, lr_reduce, tensorboard]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f268b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Visualizing the training process\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
