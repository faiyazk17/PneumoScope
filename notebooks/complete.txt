import tensorflow as tf
from tensorflow.keras import layers, models
from tqdm.keras import TqdmCallback

# Loading and Preprocessing Data
import numpy as np
import cv2
import os

def load_data(image_folder, mask_folder, img_size=(256, 256)):
    images = []
    masks = []

    # Loop through all images and masks in their respective folders
    for img_name in os.listdir(image_folder):
        if img_name.endswith('.png') or img_name.endswith('.jpg'):
            img_path = os.path.join(image_folder, img_name)
            mask_path = os.path.join(mask_folder, img_name)

            # Load image and mask
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

            # Resize images and masks to match the model input size
            img = cv2.resize(img, img_size)
            mask = cv2.resize(mask, img_size)

            # Normalize the image
            img = img / 255.0  # scaling between 0 and 1
            mask = mask / 255.0  # scaling mask between 0 and 1

            images.append(img)
            masks.append(mask)

    # Convert lists to numpy arrays
    images = np.array(images)
    masks = np.array(masks)

    # Add an extra dimension for channel (since the model expects 3D tensors)
    images = np.expand_dims(images, axis=-1)
    masks = np.expand_dims(masks, axis=-1)

    return images, masks

# 1. Defining reusable conv block
def conv_block(inputs, num_filters):
    x = layers.Conv2D(num_filters, (3, 3), padding='same',
                      activation='relu')(inputs)
    x = layers.Conv2D(num_filters, (3, 3),
                      padding='same', activation='relu')(x)
    return x

# 2. Encoder path (downsampling)
# This part of the model extracts features from the input image
# by applying a series of convolutional layers followed by max pooling
inputs = layers.Input((256, 256, 1)) # shape of greyscale chest xrays

c1 = conv_block(inputs, 64) # 64 filters in first conv block
p1 = layers.MaxPooling2D((2,2))(c1) # downsample by 2x (halves the image size by pooling)

c2 = conv_block(p1, 128) # 128 filters in second conv block
p2 = layers.MaxPooling2D((2,2))(c2) # downsample by 2x

c3 = conv_block(p2, 256) # 256 filters in third conv block
p3 = layers.MaxPooling2D((2,2))(c3) # downsample by 2x

c4 = conv_block(p3, 512) # 512 filters in fourth conv block
p4 = layers.MaxPooling2D((2,2))(c4) # downsample by 2x

# 3. Bottleneck layer
# This is the deepest layer of the model, where the most abstract features are learned
bottleneck = conv_block(p4, 1024) # 1024 filters in bottleneck conv block

#4. Decoder path (upsampling)
# The decoder path mirrors the encoder path, using transposed convolutions to upsample the feature maps
# and concatenate them with the corresponding feature maps from the encoder path
u1 = layers.UpSampling2D((2,2))(bottleneck) # upsample by 2x
u1 = layers.Concatenate()([u1, c4]) # concatenate with encoder feature map
c5 = conv_block(u1, 512) # 512 filters in fifth conv block

u2 = layers.UpSampling2D((2,2))(c5) # upsample by 2x
u2 = layers.Concatenate()([u2, c3]) # concatenate with encoder feature map
c6 = conv_block(u2, 256) # 256 filters in sixth conv block

u3 = layers.UpSampling2D((2,2))(c6) # upsample by 2x
u3 = layers.Concatenate()([u3, c2]) # concatenate with encoder feature map
c7 = conv_block(u3, 128) # 128 filters in seventh conv block

u4 = layers.UpSampling2D((2,2))(c7) # upsample by 2x
u4 = layers.Concatenate()([u4, c1]) # concatenate with encoder feature map
c8 = conv_block(u4, 64) # 64 filters in eighth conv block

# 5. Output layer
# The final layer of the model produces the segmentation mask
output = layers.Conv2D(1, (1,1), activation='sigmoid')(c8) # final output layer with 1 filter (binary segmentation)

# 6. Creating the model
# The model is created by specifying the input and output layers
model = models.Model(inputs=[inputs], outputs=[output]) # create the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # compile the model with Adam optimizer and binary crossentropy loss



# Load your data
image_folder = '../data/images'  # path to your images
mask_folder = '../data/masks'  # path to your masks
X, y = load_data(image_folder, mask_folder)

# Split the data into training and validation sets
from sklearn.model_selection import train_test_split
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Ensure TensorFlow is installed
%pip install tensorflow

from tensorflow.keras.callbacks import LambdaCallback

print_callback = LambdaCallback(
    on_epoch_end=lambda epoch, logs: print(f"Epoch {epoch + 1}: Loss={logs['loss']:.4f}, Val_Loss={logs['val_loss']:.4f}")
)

print("âœ… Starting model training...")

# 7. Training the model
history = model.fit(
    X_train, y_train,
    validation_data = (X_val, y_val),
    batch_size = 4,
    epochs = 1,
    callbacks = [print_callback]
)

